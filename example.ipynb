{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example on Credit Risk data set\n",
    "Here you can find a simple example on how to setup and run CoGS to find a counterfactual explanation for an application concerning financial credit risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cogs.evolution import Evolution\n",
    "from cogs.fitness import gower_fitness_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also set up the random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set\n",
    "Next, we load the data set \"South German Credit\", which concerns learning a model of whether providing a financial credit to a user may be risky.\n",
    "\n",
    "See https://archive.ics.uci.edu/ml/datasets/South+German+Credit+%28UPDATE%29 for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set & do some pre-processing\n",
    "df = pd.read_csv(\"south_german_credit.csv\")\n",
    "categorical_feature_names = ['purpose', 'personal_status_sex',\n",
    "    'other_debtors', 'other_installment_plans', 'telephone', 'foreign_worker']\n",
    "# Note: some other features are indices (categories in which the order matters), treated as numerical here for simplicity\n",
    "label_name = 'credit_risk'\n",
    "desired_class = 1 # this means \"low risk\"\n",
    "\n",
    "for feat in categorical_feature_names:\n",
    "    df[feat] = pd.Categorical(df[feat])\n",
    "    df[feat] = df[feat].cat.codes\n",
    "feature_names = list(df.columns)\n",
    "feature_names.remove(label_name)\n",
    "\n",
    "# Prepare data to be in numpy format, as typically used to train a scikit-learn model\n",
    "X = df[feature_names].to_numpy()\n",
    "y = df[label_name].to_numpy().astype(int)\n",
    "# Assume we have a specific train & test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "We train a random forest model that acts as the \"black-box\" that, e.g., a bank may use to (help) decide whether to grant the credir or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train black-box model (bbm)\n",
    "# (we do not one-hot-encode here for simplicity, but you can use robust_cfe/blackbox_with_preproc.py to easily do that)\n",
    "bbm = RandomForestClassifier(random_state=SEED)\n",
    "bbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick the user\n",
    "Next, we simulate to have a user for whom the decision of the black-box model is undesired. \n",
    "For example, let's pick the last point in the test set for which the prediction is unfavourable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's consider, e.g., the last test sample for which an undesired decision is given\n",
    "p = bbm.predict(X_test)\n",
    "idx = np.argwhere(p != desired_class).squeeze()[-1]\n",
    "x = X_test[idx] # this is our unhappy user!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoGS\n",
    "We are almost ready to now use CoGS to find a counterfactual explanation for our unhappy user `x`.\n",
    "First, though, we need to provide CoGS with:\n",
    "1) Intervals within which the search takes place (for categorical features, which categories are possible)\n",
    "2) The indices of categorical features\n",
    "3) Potential plausibility constraints (e.g., the age of a person cannot become lower than it is)\n",
    "\n",
    "All of these three must be provided as lists that have the same order, in particular the order used to list the feature in `X_train` and `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Some preparation for CoGS\n",
    "\n",
    "# Set up search bounds\n",
    "feature_intervals = list()\n",
    "for i, feat in enumerate(feature_names):\n",
    "  if feat in categorical_feature_names:\n",
    "    interval_i = np.unique(X_train[:,i])\n",
    "  else:\n",
    "    interval_i = (np.min(X_train[:,i]), np.max(X_train[:,i]))\n",
    "  feature_intervals.append(interval_i)\n",
    "\n",
    "# Set up which feature indices are categorical\n",
    "indices_categorical_features = [i for i, feat in enumerate(feature_names) if feat in categorical_feature_names]\n",
    "\n",
    "# Let's also set up a plausibility constraint for the feature \"age\"\n",
    "pcs = ['>=' if feat=='age' else None for feat in feature_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now setup the hyper-parameters of CoGS, and then run the search!\n",
    "We put some comments to explain what they mean in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cogs = Evolution(\n",
    "        # hyper-parameters of the problem (required!)\n",
    "        x=x,  # the unhappy user\n",
    "        fitness_function=gower_fitness_function,  # a classic fitness function for counterfactual explanations\n",
    "        fitness_function_kwargs={'blackbox':bbm,'desired_class': desired_class},  # these must be passed for the fitness function to work\n",
    "        feature_intervals=feature_intervals,  # intervals within which the search operates\n",
    "        indices_categorical_features=indices_categorical_features,  # the indices of the features that are categorical\n",
    "        plausibility_constraints=pcs, # can be \"None\" if no constraints need to be set\n",
    "        # hyper-parameters of the evolution (all optional)\n",
    "        evolution_type='classic', # the type of evolution, classic works quite  well\n",
    "        population_size=1000,   # how many candidate counterfactual examples to evolve simultaneously\n",
    "        n_generations=100,  # number of iterations for the evolution\n",
    "        selection_name='tournament_4', # selection pressure\n",
    "        init_temperature=0.8, # how \"far\" from x we initialize\n",
    "        num_features_mutation_strength=0.25, # strength of random mutations for numerical features\n",
    "        num_features_mutation_strength_decay=0.5, # decay for the hyper-param. above\n",
    "        num_features_mutation_strength_decay_generations=[50,75,90], # when to apply the decay\n",
    "        # others\n",
    "        verbose=True  # logs progress at every generation \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ready to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation: 1 best fitness: -0.293837432487357 avg. fitness: -0.5214562185233141\n",
      "generation: 2 best fitness: -0.2510893680668098 avg. fitness: -0.45388250049116696\n",
      "generation: 3 best fitness: -0.2323692193952797 avg. fitness: -0.40303163962654004\n",
      "generation: 4 best fitness: -0.20012311659357698 avg. fitness: -0.34679752948384396\n",
      "generation: 5 best fitness: -0.14970165842315736 avg. fitness: -0.29572311736676454\n",
      "generation: 6 best fitness: -0.14473293186032618 avg. fitness: -0.2542540768340204\n",
      "generation: 7 best fitness: -0.09679574332982878 avg. fitness: -0.2142091158529426\n",
      "generation: 8 best fitness: -0.08342069842620103 avg. fitness: -0.1790862971543234\n",
      "generation: 9 best fitness: -0.05696144238579127 avg. fitness: -0.14657272079943426\n",
      "generation: 10 best fitness: -0.030340551858586248 avg. fitness: -0.11739392672781657\n",
      "generation: 11 best fitness: -0.030207758431344642 avg. fitness: -0.09339445268296587\n",
      "generation: 12 best fitness: -0.02911020994296238 avg. fitness: -0.07518509597686784\n",
      "generation: 13 best fitness: -0.028988430159096048 avg. fitness: -0.06429017732665067\n",
      "generation: 14 best fitness: -0.028988430159096048 avg. fitness: -0.05036606286672384\n",
      "generation: 15 best fitness: -0.028260972373682056 avg. fitness: -0.043116293440382536\n",
      "generation: 16 best fitness: -0.028260972373682056 avg. fitness: -0.038280288036923404\n",
      "generation: 17 best fitness: -0.028260972373682056 avg. fitness: -0.03522971558654575\n",
      "generation: 18 best fitness: -0.02823719225464512 avg. fitness: -0.03369204395842144\n",
      "generation: 19 best fitness: -0.02823719225464512 avg. fitness: -0.032519131295800204\n",
      "generation: 20 best fitness: -0.02823719225464512 avg. fitness: -0.03158729595827639\n",
      "generation: 21 best fitness: -0.02823719225464512 avg. fitness: -0.03148039734261115\n",
      "generation: 22 best fitness: -0.02823719225464512 avg. fitness: -0.03109899753447578\n",
      "generation: 23 best fitness: -0.02823719225464512 avg. fitness: -0.031581932142580656\n",
      "generation: 24 best fitness: -0.02823719225464512 avg. fitness: -0.03129742777329243\n",
      "generation: 25 best fitness: -0.02823719225464512 avg. fitness: -0.03064112128609434\n",
      "generation: 26 best fitness: -0.02823719225464512 avg. fitness: -0.0305080570461899\n",
      "generation: 27 best fitness: -0.02816784349244232 avg. fitness: -0.030505193854487665\n",
      "generation: 28 best fitness: -0.02816784349244232 avg. fitness: -0.030117680853731704\n",
      "generation: 29 best fitness: -0.02816784349244232 avg. fitness: -0.030825780772078582\n",
      "generation: 30 best fitness: -0.02816784349244232 avg. fitness: -0.031125172277199915\n",
      "generation: 31 best fitness: -0.028139728780490005 avg. fitness: -0.030530800337752566\n",
      "generation: 32 best fitness: -0.028139728780490005 avg. fitness: -0.030906555846685103\n",
      "generation: 33 best fitness: -0.028139728780490005 avg. fitness: -0.030683383721900173\n",
      "generation: 34 best fitness: -0.028139728780490005 avg. fitness: -0.030909991275977072\n",
      "generation: 35 best fitness: -0.028139728780490005 avg. fitness: -0.030456300936304737\n",
      "generation: 36 best fitness: -0.028139728780490005 avg. fitness: -0.030929207560736225\n",
      "generation: 37 best fitness: -0.028139728780490005 avg. fitness: -0.03095399334196638\n",
      "generation: 38 best fitness: -0.028139728780490005 avg. fitness: -0.03037294659202554\n",
      "generation: 39 best fitness: -0.028139728780490005 avg. fitness: -0.030579020043190564\n",
      "generation: 40 best fitness: -0.028139728780490005 avg. fitness: -0.030833402081868536\n",
      "generation: 41 best fitness: -0.028139728780490005 avg. fitness: -0.030326384454723448\n",
      "generation: 42 best fitness: -0.028139728780490005 avg. fitness: -0.03027786038360844\n",
      "generation: 43 best fitness: -0.028139728780490005 avg. fitness: -0.03039435827404348\n",
      "generation: 44 best fitness: -0.028139728780490005 avg. fitness: -0.030267486993852472\n",
      "generation: 45 best fitness: -0.028139728780490005 avg. fitness: -0.030727834892584904\n",
      "generation: 46 best fitness: -0.028139728780490005 avg. fitness: -0.031053003427376373\n",
      "generation: 47 best fitness: -0.028139728780490005 avg. fitness: -0.03077409613296917\n",
      "generation: 48 best fitness: -0.028139728780490005 avg. fitness: -0.03108484746156634\n",
      "generation: 49 best fitness: -0.028139728780490005 avg. fitness: -0.03127319636617112\n",
      "generation: 50 best fitness: -0.028139728780490005 avg. fitness: -0.031079711701971255\n",
      "generation: 51 best fitness: -0.028139728780490005 avg. fitness: -0.030708521353430402\n",
      "generation: 52 best fitness: -0.028139728780490005 avg. fitness: -0.03014192954576342\n",
      "generation: 53 best fitness: -0.028139728780490005 avg. fitness: -0.03040731354334489\n",
      "generation: 54 best fitness: -0.028139728780490005 avg. fitness: -0.030486122825134254\n",
      "generation: 55 best fitness: -0.028139728780490005 avg. fitness: -0.030391685603504085\n",
      "generation: 56 best fitness: -0.028139728780490005 avg. fitness: -0.030776634863285163\n",
      "generation: 57 best fitness: -0.028139728780490005 avg. fitness: -0.03024384023700181\n",
      "generation: 58 best fitness: -0.028139728780490005 avg. fitness: -0.031209046530532206\n",
      "generation: 59 best fitness: -0.028139728780490005 avg. fitness: -0.030909923212285646\n",
      "generation: 60 best fitness: -0.028139728780490005 avg. fitness: -0.031432363051087625\n",
      "generation: 61 best fitness: -0.028139728780490005 avg. fitness: -0.03150262455047486\n",
      "generation: 62 best fitness: -0.028139728780490005 avg. fitness: -0.03180236802945202\n",
      "generation: 63 best fitness: -0.028139728780490005 avg. fitness: -0.030955824697850135\n",
      "generation: 64 best fitness: -0.028139728780490005 avg. fitness: -0.03110042736822616\n",
      "generation: 65 best fitness: -0.028139728780490005 avg. fitness: -0.030878017490987526\n",
      "generation: 66 best fitness: -0.028139728780490005 avg. fitness: -0.03090191400366564\n",
      "generation: 67 best fitness: -0.028139728780490005 avg. fitness: -0.03171479506103069\n",
      "generation: 68 best fitness: -0.028139728780490005 avg. fitness: -0.030703732442928417\n",
      "generation: 69 best fitness: -0.028130734818062476 avg. fitness: -0.030890164052237802\n",
      "generation: 70 best fitness: -0.028130734818062476 avg. fitness: -0.031371148994087064\n",
      "generation: 71 best fitness: -0.028130734818062476 avg. fitness: -0.0312263177397472\n",
      "generation: 72 best fitness: -0.028130734818062476 avg. fitness: -0.03162365967437895\n",
      "generation: 73 best fitness: -0.028130734818062476 avg. fitness: -0.031648026511070376\n",
      "generation: 74 best fitness: -0.028130734818062476 avg. fitness: -0.03103331074370824\n",
      "generation: 75 best fitness: -0.028130734818062476 avg. fitness: -0.031336950617018126\n",
      "generation: 76 best fitness: -0.028130734818062476 avg. fitness: -0.03122712759781176\n",
      "generation: 77 best fitness: -0.028130734818062476 avg. fitness: -0.031197535674265146\n",
      "generation: 78 best fitness: -0.028130734818062476 avg. fitness: -0.030749045341076153\n",
      "generation: 79 best fitness: -0.028130734818062476 avg. fitness: -0.0311944824978004\n",
      "generation: 80 best fitness: -0.028130734818062476 avg. fitness: -0.030902711955978594\n",
      "generation: 81 best fitness: -0.028130734818062476 avg. fitness: -0.030543756232913367\n",
      "generation: 82 best fitness: -0.028130734818062476 avg. fitness: -0.03081988481659994\n",
      "generation: 83 best fitness: -0.02812995991815927 avg. fitness: -0.030186520158377028\n",
      "generation: 84 best fitness: -0.02812995991815927 avg. fitness: -0.03081505685675434\n",
      "generation: 85 best fitness: -0.02812995991815927 avg. fitness: -0.030972012351815566\n",
      "generation: 86 best fitness: -0.02812995991815927 avg. fitness: -0.030245160121237534\n",
      "generation: 87 best fitness: -0.02812995991815927 avg. fitness: -0.030366268809947236\n",
      "generation: 88 best fitness: -0.02812995991815927 avg. fitness: -0.030842335498379097\n",
      "generation: 89 best fitness: -0.02812995991815927 avg. fitness: -0.03124191176333099\n",
      "generation: 90 best fitness: -0.02812995991815927 avg. fitness: -0.030560790214414265\n",
      "generation: 91 best fitness: -0.02812995991815927 avg. fitness: -0.030852502802349697\n",
      "generation: 92 best fitness: -0.02812995991815927 avg. fitness: -0.03034608939710384\n",
      "generation: 93 best fitness: -0.02812995991815927 avg. fitness: -0.031400576136464915\n",
      "generation: 94 best fitness: -0.02812995991815927 avg. fitness: -0.030770721784718603\n",
      "generation: 95 best fitness: -0.02812995991815927 avg. fitness: -0.030620484575346787\n",
      "generation: 96 best fitness: -0.02812995991815927 avg. fitness: -0.03150053727144128\n",
      "generation: 97 best fitness: -0.02812995991815927 avg. fitness: -0.030543305404700745\n",
      "generation: 98 best fitness: -0.02812995991815927 avg. fitness: -0.030669235552589127\n",
      "generation: 99 best fitness: -0.02812995991815927 avg. fitness: -0.030118430888253448\n",
      "generation: 100 best fitness: -0.02812995991815927 avg. fitness: -0.030445523359501105\n"
     ]
    }
   ],
   "source": [
    "cogs.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counterfactual explanation\n",
    "Now that CoGS has terminated, we can look at its result.\n",
    "The field `cogs.elite` contains the best-found counterfactual example, i.e., a point `x'` for which `bbm(x')=desired_class`.\n",
    "The relative counterfactual explanation is simply `x'-x` (there exist more involved definitions of counterfactual explanations, here we use this simple one).\n",
    "Let's take a look at what the user needs to do to obtain the desired class, i.e., be granted the loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Here's the explanation:\n",
      " Feature savings should change by +0.50079\n"
     ]
    }
   ],
   "source": [
    "# Get the best-found counterfactual example (called elite)\n",
    "cf_example = cogs.elite\n",
    "cf_explanation = cogs.elite - x\n",
    "\n",
    "# Show counterfactual explanation\n",
    "if bbm.predict([cf_example])[0] == desired_class:\n",
    "  print(\"Success! Here's the explanation:\")\n",
    "  for i, feat in enumerate(feature_names):\n",
    "    cf_expl_i = cf_explanation[i]\n",
    "    if cf_expl_i != 0:\n",
    "      print(\" Feature {} should change by {}{:.5f}\".format(feat,\"+\" if np.sign(cf_expl_i) > 0 else \"-\",cf_expl_i))\n",
    "else:\n",
    "  print(\"Failed to find a counterfactual explanation for the desired class :(\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "82b2f7e49a54dfc9e19a85f649bd0ef29fcdbc801e6c42932c693ea93cc5c6ab"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
